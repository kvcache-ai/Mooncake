#!/usr/bin/env python3
import asyncio
import threading
import time
import torch
import numpy as np
import coro_rpc_transfer

def tensor_handler(ctx, view):
    """
    å¤„ç†æ¥æ”¶åˆ°çš„tensoræ•°æ®çš„å›è°ƒå‡½æ•°
    ctx: py_rpc_context å¯¹è±¡
    view: memoryview å¯¹è±¡åŒ…å«æ¥æ”¶åˆ°çš„æ•°æ®
    """
    print(f"Received tensor data, size: {len(view)} bytes")
    print()
    
    # è¿™é‡Œå¯ä»¥æ·»åŠ ä½ çš„tensorå¤„ç†é€»è¾‘
    # ä¾‹å¦‚ï¼šä¿å­˜åˆ°æ–‡ä»¶ã€è¿›è¡Œè®¡ç®—ç­‰
    response_data = b"Tensor received and processed successfully"
    response_buffer = memoryview(response_data)
    
    def done_callback(success):
        if success:
            print("Response sent successfully")
        else:
            print("Failed to send response")
    
    ctx.response_msg(response_buffer, done_callback)

def start_server():
    """å¯åŠ¨RPCæœåŠ¡å™¨"""
    print("Starting RPC server...")

    server = coro_rpc_transfer.coro_rpc_server(
        4, 
        "127.0.0.1:8801", 
        tensor_handler, 
        10 
    )
    
    print("Server created, starting...")
    
    # å¯åŠ¨æœåŠ¡å™¨
    success = server.async_start()
    
    if success:
        print("âœ… RPC Server started successfully on 127.0.0.1:8801")
        print("Available endpoints:")
        print("  - handle_msg: å¤„ç†æ™®é€šæ¶ˆæ¯")
        print("  - handle_tensor: å¤„ç†tensorä¼ è¾“")
        print("  - reflect_tensor: å›æ˜¾tensor")
        print("\nServer is running... Press Ctrl+C to stop")
        
        try:
            # ä¿æŒæœåŠ¡å™¨è¿è¡Œ
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\nğŸ›‘ Server stopping...")
    else:
        print("âŒ Failed to start server")
        return False
    
    return True

if __name__ == "__main__":
    start_server()