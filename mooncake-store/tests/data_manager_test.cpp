#include <glog/logging.h>
#include <gtest/gtest.h>
#include <json/json.h>
#include <memory>
#include <string>
#include <thread>
#include <vector>
#include <cstring>
#include <unordered_map>
#include <chrono>
#include <mutex>

#include "data_manager.h"
#include "tiered_cache/tiered_backend.h"
#include "transfer_engine.h"
#include "types.h"
#include "utils.h"

namespace mooncake {

// Helper function to parse JSON string
static bool parseJsonString(const std::string& json_str, Json::Value& value,
                            std::string* error_msg = nullptr) {
    Json::CharReaderBuilder builder;
    std::unique_ptr<Json::CharReader> reader(builder.newCharReader());
    std::string errs;

    bool success = reader->parse(
        json_str.data(), json_str.data() + json_str.size(), &value, &errs);
    if (!success && error_msg) {
        *error_msg = errs;
    }
    return success;
}

// Test fixture for DataManager tests
class DataManagerTest : public ::testing::Test {
   protected:
    void SetUp() override {
        google::InitGoogleLogging("DataManagerTest");
        FLAGS_logtostderr = 1;

        // Create a minimal TransferEngine
        transfer_engine_ = std::make_shared<TransferEngine>(false);

        // Create TieredBackend with DRAM tier configuration
        std::string json_config_str = R"({
            "tiers": [
                {
                    "type": "DRAM",
                    "capacity": 1073741824,
                    "priority": 10,
                    "tags": ["fast", "local"],
                    "allocator_type": "OFFSET"
                }
            ]
        })";
        Json::Value config;
        ASSERT_TRUE(parseJsonString(json_config_str, config));

        tiered_backend_ = std::make_unique<TieredBackend>();
        // transfer_engine_ is nullptr when initializing tiered_backend_
        // only for local access test
        auto init_result = tiered_backend_->Init(config, nullptr, nullptr);
        ASSERT_TRUE(init_result.has_value())
            << "Failed to initialize TieredBackend: " << init_result.error();

        // Verify tier was created successfully
        auto tier_views = tiered_backend_->GetTierViews();
        ASSERT_EQ(tier_views.size(), 1)
            << "Expected 1 tier, got " << tier_views.size();
        saved_tier_id_ = tier_views[0].id;

        // Create DataManager
        data_manager_ = std::make_unique<DataManager>(
            std::move(tiered_backend_), transfer_engine_);
    }

    void TearDown() override {
        data_manager_.reset();
        tiered_backend_.reset();
        transfer_engine_.reset();
        google::ShutdownGoogleLogging();
    }

    // Helper: Get tier ID from backend
    std::optional<UUID> GetTierId() {
        if (saved_tier_id_.has_value()) {
            return saved_tier_id_;
        }
        return std::nullopt;
    }

    // Helper: Create test data buffer
    std::unique_ptr<char[]> CreateTestData(
        size_t size, const std::string& pattern = "test") {
        auto buffer = std::make_unique<char[]>(size);
        for (size_t i = 0; i < size; ++i) {
            buffer[i] = pattern[i % pattern.size()];
        }
        return buffer;
    }

    // Helper: Convert string to unique_ptr<char[]> for Put
    std::unique_ptr<char[]> StringToBuffer(const std::string& str) {
        auto buffer = std::make_unique<char[]>(str.size());
        std::memcpy(buffer.get(), str.data(), str.size());
        return buffer;
    }

    // Wrapper methods to access private DataManager methods
    // These allow derived test classes (generated by TEST_F) to access private
    // methods
    tl::expected<void, ErrorCode> CallTransferDataToRemote(
        AllocationHandle handle,
        const std::vector<RemoteBufferDesc>& dest_buffers) {
        return data_manager_->TransferDataToRemote(handle, dest_buffers);
    }

    tl::expected<void, ErrorCode> CallTransferDataFromRemote(
        AllocationHandle handle,
        const std::vector<RemoteBufferDesc>& src_buffers) {
        return data_manager_->TransferDataFromRemote(handle, src_buffers);
    }

    std::unique_ptr<DataManager> data_manager_;
    std::unique_ptr<TieredBackend> tiered_backend_;
    std::shared_ptr<TransferEngine> transfer_engine_;
    std::optional<UUID> saved_tier_id_;
};

// Test Put operation - success case
TEST_F(DataManagerTest, PutSuccess) {
    const std::string key = "test_key";
    const std::string test_data = "Hello, World!";
    const size_t data_size = test_data.size();

    auto buffer = StringToBuffer(test_data);
    auto result = data_manager_->Put(key, std::move(buffer), data_size);

    ASSERT_TRUE(result.has_value())
        << "Put failed with error: " << toString(result.error());

    // Verify the key exists in the backend
    auto get_result = data_manager_->Get(key);
    ASSERT_TRUE(get_result.has_value()) << "Get failed after Put";

    // DFX: Verify handle and buffer validity
    auto handle = get_result.value();
    ASSERT_NE(handle, nullptr) << "Handle should not be null";
    ASSERT_NE(handle->loc.data.buffer, nullptr) << "Buffer should not be null";
    ASSERT_NE(handle->loc.tier, nullptr) << "Tier pointer should not be null";

    EXPECT_EQ(handle->loc.data.buffer->size(), data_size);
}

// Test Put operation - allocation failure (by using huge size)
TEST_F(DataManagerTest, PutAllocationFailure) {
    const std::string key = "test_key";
    // Try to allocate more than available capacity (1GB)
    const size_t huge_size = 2ULL * 1024 * 1024 * 1024;  // 2GB

    auto test_data = CreateTestData(1024);
    auto result = data_manager_->Put(key, std::move(test_data), huge_size);

    ASSERT_FALSE(result.has_value());
    EXPECT_EQ(result.error(), ErrorCode::NO_AVAILABLE_HANDLE);
}

// Test Put with tier_id
TEST_F(DataManagerTest, PutWithTierId) {
    const std::string key = "test_key_with_tier";
    const std::string test_data = "Test data with tier";
    auto tier_id = GetTierId();

    ASSERT_TRUE(tier_id.has_value()) << "No tier available";

    auto buffer = StringToBuffer(test_data);
    auto result =
        data_manager_->Put(key, std::move(buffer), test_data.size(), tier_id);

    ASSERT_TRUE(result.has_value()) << "Put with tier_id failed";

    // Verify we can get it back
    auto get_result = data_manager_->Get(key, tier_id);
    ASSERT_TRUE(get_result.has_value());
}

// Test Get operation - success case
TEST_F(DataManagerTest, GetSuccess) {
    const std::string key = "test_get_key";
    const std::string test_data = "Test data for Get";

    // First, put the data
    auto buffer = StringToBuffer(test_data);
    auto put_result =
        data_manager_->Put(key, std::move(buffer), test_data.size());
    ASSERT_TRUE(put_result.has_value()) << "Put failed in Get test";

    // Then, get it
    auto get_result = data_manager_->Get(key);

    ASSERT_TRUE(get_result.has_value())
        << "Get failed with error: " << toString(get_result.error());
    ASSERT_NE(get_result.value()->loc.data.buffer, nullptr)
        << "Buffer should not be null";
    EXPECT_EQ(get_result.value()->loc.data.buffer->size(), test_data.size());
}

// Test Get operation - key not found
TEST_F(DataManagerTest, GetKeyNotFound) {
    const std::string key = "non_existent_key";

    auto result = data_manager_->Get(key);

    ASSERT_FALSE(result.has_value());
    // TieredBackend returns INVALID_KEY for not found keys
    EXPECT_EQ(result.error(), ErrorCode::INVALID_KEY);
}

// Test Get with tier_id
TEST_F(DataManagerTest, GetWithTierId) {
    const std::string key = "test_get_tier_key";
    const std::string test_data = "Test data";
    auto tier_id = GetTierId();

    ASSERT_TRUE(tier_id.has_value()) << "No tier available";

    // Put with specific tier
    auto buffer = StringToBuffer(test_data);
    auto put_result =
        data_manager_->Put(key, std::move(buffer), test_data.size(), tier_id);
    ASSERT_TRUE(put_result.has_value());

    // Get with same tier
    auto get_result = data_manager_->Get(key, tier_id);
    ASSERT_TRUE(get_result.has_value());
    ASSERT_NE(get_result.value()->loc.data.buffer, nullptr)
        << "Buffer should not be null";
    EXPECT_EQ(get_result.value()->loc.data.buffer->size(), test_data.size());
}

// Test Delete operation - success case
TEST_F(DataManagerTest, DeleteSuccess) {
    const std::string key = "test_delete_key";
    const std::string test_data = "Test data for Delete";

    // First, put the data
    auto buffer = StringToBuffer(test_data);
    auto put_result =
        data_manager_->Put(key, std::move(buffer), test_data.size());
    ASSERT_TRUE(put_result.has_value());

    // Then, delete it
    auto delete_result = data_manager_->Delete(key);

    ASSERT_TRUE(delete_result.has_value())
        << "Delete failed with error: " << toString(delete_result.error());

    // Verify it's deleted
    auto get_result = data_manager_->Get(key);
    ASSERT_FALSE(get_result.has_value());
    EXPECT_EQ(get_result.error(), ErrorCode::INVALID_KEY);
}

// Test Delete operation - key not found
TEST_F(DataManagerTest, DeleteKeyNotFound) {
    const std::string key = "non_existent_key";

    auto result = data_manager_->Delete(key);

    ASSERT_FALSE(result.has_value())
        << "Delete should fail for non-existent key";
    // Verify it returns appropriate error code
    EXPECT_NE(result.error(), ErrorCode::OK);
}

// Test Delete with tier_id
TEST_F(DataManagerTest, DeleteWithTierId) {
    const std::string key = "test_delete_tier_key";
    const std::string test_data = "Test data";
    auto tier_id = GetTierId();

    ASSERT_TRUE(tier_id.has_value()) << "No tier available";

    // Put with specific tier
    auto buffer = StringToBuffer(test_data);
    auto put_result =
        data_manager_->Put(key, std::move(buffer), test_data.size(), tier_id);
    ASSERT_TRUE(put_result.has_value());

    // Delete with same tier
    auto delete_result = data_manager_->Delete(key, tier_id);
    ASSERT_TRUE(delete_result.has_value())
        << "Delete failed with error: " << toString(delete_result.error());

    // Verify it's deleted
    auto get_result = data_manager_->Get(key, tier_id);
    ASSERT_FALSE(get_result.has_value());
}

// Test concurrent Put operations
TEST_F(DataManagerTest, ConcurrentPut) {
    const int num_keys = 10;
    std::vector<std::string> keys;
    for (int i = 0; i < num_keys; ++i) {
        keys.push_back("concurrent_key_" + std::to_string(i));
    }

    // Put all keys concurrently
    std::vector<tl::expected<void, ErrorCode>> results(num_keys);
    std::vector<std::thread> threads;

    for (int i = 0; i < num_keys; ++i) {
        threads.emplace_back([this, &keys, &results, i]() {
            std::string data = "data_" + std::to_string(i);
            auto buffer = StringToBuffer(data);
            results[i] =
                data_manager_->Put(keys[i], std::move(buffer), data.size());
        });
    }

    for (auto& t : threads) {
        t.join();
    }

    // Verify all succeeded
    for (int i = 0; i < num_keys; ++i) {
        ASSERT_TRUE(results[i].has_value())
            << "Put failed for key: " << keys[i];
    }

    // Verify all can be retrieved
    for (int i = 0; i < num_keys; ++i) {
        auto get_result = data_manager_->Get(keys[i]);
        ASSERT_TRUE(get_result.has_value())
            << "Get failed for key: " << keys[i];
    }
}

// Test Put-Get-Delete sequence
TEST_F(DataManagerTest, PutGetDeleteSequence) {
    const std::string key = "sequence_test_key";
    const std::string test_data = "Sequence test data";

    // Put
    auto buffer = StringToBuffer(test_data);
    auto put_result =
        data_manager_->Put(key, std::move(buffer), test_data.size());
    ASSERT_TRUE(put_result.has_value());

    // Get
    auto get_result = data_manager_->Get(key);
    ASSERT_TRUE(get_result.has_value());
    ASSERT_NE(get_result.value()->loc.data.buffer, nullptr)
        << "Buffer should not be null";
    EXPECT_EQ(get_result.value()->loc.data.buffer->size(), test_data.size());

    // Delete
    auto delete_result = data_manager_->Delete(key);
    ASSERT_TRUE(delete_result.has_value())
        << "Delete failed with error: " << toString(delete_result.error());

    // Verify deleted
    auto get_after_delete = data_manager_->Get(key);
    ASSERT_FALSE(get_after_delete.has_value());
}

// ========== ReadRemoteData/WriteRemoteData Tests ==========

// Test ReadRemoteData with non-existent key
TEST_F(DataManagerTest, ReadRemoteDataKeyNotFound) {
    const std::string key = "non_existent_key";

    std::vector<RemoteBufferDesc> dest_buffers = {{"segment1", 0x1000, 1024}};

    auto result = data_manager_->ReadRemoteData(key, dest_buffers);

    ASSERT_FALSE(result.has_value());
    EXPECT_EQ(result.error(), ErrorCode::INVALID_KEY);
}

// Test ReadRemoteData with empty buffers
TEST_F(DataManagerTest, ReadRemoteDataEmptyBuffers) {
    const std::string key = "test_key";
    const std::string test_data = "Hello";

    auto buffer = StringToBuffer(test_data);
    ASSERT_TRUE(data_manager_->Put(key, std::move(buffer), test_data.size())
                    .has_value());

    std::vector<RemoteBufferDesc> empty_buffers;
    auto result = data_manager_->ReadRemoteData(key, empty_buffers);

    ASSERT_FALSE(result.has_value());
    EXPECT_EQ(result.error(), ErrorCode::INVALID_PARAMS);
}

// Test WriteRemoteData with invalid buffer (zero size)
TEST_F(DataManagerTest, WriteRemoteDataInvalidBuffer) {
    const std::string key = "test_key";

    std::vector<RemoteBufferDesc> invalid_buffers = {
        {"segment1", 0x1000, 0}  // Zero size
    };

    auto result = data_manager_->WriteRemoteData(key, invalid_buffers);

    ASSERT_FALSE(result.has_value());
    EXPECT_EQ(result.error(), ErrorCode::INVALID_PARAMS);
}

// Test WriteRemoteData with invalid buffer (null address)
TEST_F(DataManagerTest, WriteRemoteDataNullAddress) {
    const std::string key = "test_key";

    std::vector<RemoteBufferDesc> invalid_buffers = {
        {"segment1", 0, 1024}  // Null address
    };

    auto result = data_manager_->WriteRemoteData(key, invalid_buffers);

    ASSERT_FALSE(result.has_value());
    EXPECT_EQ(result.error(), ErrorCode::INVALID_PARAMS);
}

// Test WriteRemoteData with empty buffers
TEST_F(DataManagerTest, WriteRemoteDataEmptyBuffers) {
    const std::string key = "test_key";

    std::vector<RemoteBufferDesc> empty_buffers;
    auto result = data_manager_->WriteRemoteData(key, empty_buffers);

    // Empty buffers should be handled - total_size will be 0
    // This is a valid edge case that should fail at allocation
    ASSERT_FALSE(result.has_value());
}

// Test large data storage and retrieval
TEST_F(DataManagerTest, LargeDataStorage) {
    const std::string key = "large_data_key";
    const size_t large_size = 10 * 1024 * 1024;  // 10MB

    auto large_data = CreateTestData(large_size, "LARGE");

    auto put_result =
        data_manager_->Put(key, std::move(large_data), large_size);
    ASSERT_TRUE(put_result.has_value());

    auto get_result = data_manager_->Get(key);
    ASSERT_TRUE(get_result.has_value());

    auto handle = get_result.value();
    ASSERT_EQ(handle->loc.data.buffer->size(), large_size);

    // Verify data integrity
    char* data_ptr = reinterpret_cast<char*>(handle->loc.data.buffer->data());
    for (size_t i = 0; i < 100; ++i) {  // Sample check
        EXPECT_EQ(data_ptr[i], "LARGE"[i % 5]);
    }
}

// Test multiple scatter-gather buffers
TEST_F(DataManagerTest, MultipleScatterGatherBuffers) {
    const std::string key = "scatter_gather_key";
    const std::string test_data = "ScatterGatherTestData";

    auto buffer = StringToBuffer(test_data);
    ASSERT_TRUE(data_manager_->Put(key, std::move(buffer), test_data.size())
                    .has_value());

    auto handle_result = data_manager_->Get(key);
    ASSERT_TRUE(handle_result.has_value());
    auto handle = handle_result.value();

    // Test with multiple buffers in different segments (total size >= 21)
    std::vector<RemoteBufferDesc> multi_segment_buffers = {
        {"segment_a", 0x1000, 7},
        {"segment_b", 0x2000, 7},
        {"segment_c", 0x3000, 7}};

    // Verify all parameters are valid (no empty segment names, non-zero sizes,
    // valid addresses)
    for (const auto& buf : multi_segment_buffers) {
        EXPECT_FALSE(buf.segment_name.empty());
        EXPECT_GT(buf.size, 0);
        EXPECT_NE(buf.addr, 0);
    }

    // Calculate total size
    size_t total_size = 0;
    for (const auto& buf : multi_segment_buffers) {
        total_size += buf.size;
    }
    EXPECT_GE(total_size, test_data.size());

    // Note: Actual TransferDataToRemote would require real TransferEngine setup
    // with registered segments This test validates the scatter-gather parameter
    // structure is correct
}

// Test concurrent read operations
TEST_F(DataManagerTest, ConcurrentReadOperations) {
    const std::string key = "concurrent_read_key";
    const std::string test_data = "ConcurrentTestData";

    auto buffer = StringToBuffer(test_data);
    ASSERT_TRUE(data_manager_->Put(key, std::move(buffer), test_data.size())
                    .has_value());

    const int num_threads = 10;
    std::vector<std::thread> threads;
    std::atomic<int> success_count{0};

    for (int i = 0; i < num_threads; ++i) {
        threads.emplace_back([this, &key, &success_count]() {
            auto result = data_manager_->Get(key);
            if (result.has_value()) {
                success_count++;
            }
        });
    }

    for (auto& t : threads) {
        t.join();
    }

    EXPECT_EQ(success_count, num_threads);
}

// Test data integrity across multiple operations
TEST_F(DataManagerTest, DataIntegrityAcrossOperations) {
    const std::string key = "integrity_test_key";
    const std::string original_data = "IntegrityTest_123456789";

    // Store original data
    auto buffer1 = StringToBuffer(original_data);
    ASSERT_TRUE(
        data_manager_->Put(key, std::move(buffer1), original_data.size())
            .has_value());

    // Retrieve and verify
    auto get_result1 = data_manager_->Get(key);
    ASSERT_TRUE(get_result1.has_value());
    auto handle1 = get_result1.value();

    char* ptr1 = reinterpret_cast<char*>(handle1->loc.data.buffer->data());
    std::string retrieved1(ptr1, original_data.size());
    EXPECT_EQ(retrieved1, original_data);

    // Delete the data
    ASSERT_TRUE(data_manager_->Delete(key));

    // Verify deletion
    auto get_result2 = data_manager_->Get(key);
    ASSERT_FALSE(get_result2.has_value());

    // Store new data with same key
    const std::string new_data = "NewDataForIntegrityCheck";
    auto buffer2 = StringToBuffer(new_data);
    ASSERT_TRUE(data_manager_->Put(key, std::move(buffer2), new_data.size())
                    .has_value());

    // Retrieve and verify new data
    auto get_result3 = data_manager_->Get(key);
    ASSERT_TRUE(get_result3.has_value());
    auto handle3 = get_result3.value();

    char* ptr3 = reinterpret_cast<char*>(handle3->loc.data.buffer->data());
    std::string retrieved3(ptr3, new_data.size());
    EXPECT_EQ(retrieved3, new_data);
}

// Test various key pattern formats
TEST_F(DataManagerTest, KeyPatternVariations) {
    const std::string test_data = "KeyPatternTestData";

    // Test different key formats
    std::vector<std::string> test_keys = {
        "simple_key",
        "key/with/slashes",
        "key.with.dots",
        "key-with-dashes",
        "key_with_underscores",
        "MixedCaseKey",
        "key:with:colons",
        "key123numeric456",
        "a",                    // Single character key
        std::string(100, 'x'),  // Long key (100 chars)
        "key with spaces",
        "key\twith\ttabs",
        "unicode_é”®_key"};

    for (const auto& key : test_keys) {
        auto buffer = StringToBuffer(test_data);
        auto put_result =
            data_manager_->Put(key, std::move(buffer), test_data.size());

        // Put should succeed for all valid string keys
        ASSERT_TRUE(put_result.has_value()) << "Put failed for key: " << key;

        // Get should return the same data
        auto get_result = data_manager_->Get(key);
        ASSERT_TRUE(get_result.has_value()) << "Get failed for key: " << key;
        EXPECT_EQ(get_result.value()->loc.data.buffer->size(),
                  test_data.size());

        // Verify data integrity
        char* ptr = reinterpret_cast<char*>(
            get_result.value()->loc.data.buffer->data());
        EXPECT_EQ(std::string(ptr, test_data.size()), test_data)
            << "Data mismatch for key: " << key;

        // Delete should succeed
        ASSERT_TRUE(data_manager_->Delete(key))
            << "Delete failed for key: " << key;
    }
}

// Test memory release verification through repeated allocations
TEST_F(DataManagerTest, MemoryReleaseVerification) {
    const size_t data_size = 1024 * 1024;  // 1MB per allocation
    const int iterations = 50;             // 50MB total if memory not released

    for (int i = 0; i < iterations; ++i) {
        std::string key = "memory_test_key_" + std::to_string(i);
        auto buffer = CreateTestData(data_size, "MEM");

        // Put data
        auto put_result = data_manager_->Put(key, std::move(buffer), data_size);
        ASSERT_TRUE(put_result.has_value()) << "Put failed at iteration " << i;

        // Verify data exists
        auto get_result = data_manager_->Get(key);
        ASSERT_TRUE(get_result.has_value()) << "Get failed at iteration " << i;
        EXPECT_EQ(get_result.value()->loc.data.buffer->size(), data_size);

        // Delete data to release memory
        ASSERT_TRUE(data_manager_->Delete(key))
            << "Delete failed at iteration " << i;

        // Verify deletion
        EXPECT_FALSE(data_manager_->Get(key).has_value());
    }

    // Final verification: allocate one more time to ensure memory was properly
    // released
    std::string final_key = "final_memory_test";
    auto final_buffer = CreateTestData(data_size, "FIN");
    ASSERT_TRUE(
        data_manager_->Put(final_key, std::move(final_buffer), data_size)
            .has_value());
    ASSERT_TRUE(data_manager_->Delete(final_key));
}

// Test multi-buffer validation for scatter-gather operations
TEST_F(DataManagerTest, MultiBufferValidation) {
    const std::string key = "multi_buffer_key";
    const std::string test_data =
        "MultiBufferValidationTestData123456";  // 35 bytes

    auto buffer = StringToBuffer(test_data);
    ASSERT_TRUE(data_manager_->Put(key, std::move(buffer), test_data.size())
                    .has_value());

    auto handle_result = data_manager_->Get(key);
    ASSERT_TRUE(handle_result.has_value());
    auto handle = handle_result.value();

    // Test case 1: Multiple valid buffers with exact total size
    {
        std::vector<RemoteBufferDesc> exact_buffers = {
            {"seg1", 0x1000, 10},
            {"seg2", 0x2000, 10},
            {"seg3", 0x3000, 10},
            {"seg4", 0x4000, 5}  // Total = 35 bytes
        };
        size_t total = 0;
        for (const auto& b : exact_buffers) total += b.size;
        EXPECT_EQ(total, test_data.size());
    }

    // Test case 2: Multiple valid buffers with excess capacity
    {
        std::vector<RemoteBufferDesc> excess_buffers = {
            {"seg1", 0x1000, 20}, {"seg2", 0x2000, 20}, {"seg3", 0x3000, 20}
            // Total = 60 bytes > 35 bytes
        };
        size_t total = 0;
        for (const auto& b : excess_buffers) total += b.size;
        EXPECT_GT(total, test_data.size());
    }

    // Test case 3: Mixed buffer with one invalid (empty segment name) - should
    // fail validation
    {
        std::vector<RemoteBufferDesc> mixed_invalid = {
            {"seg1", 0x1000, 10},
            {"", 0x2000, 10},  // Invalid: empty segment
            {"seg3", 0x3000, 15}};
        auto result = CallTransferDataToRemote(handle, mixed_invalid);
        EXPECT_FALSE(result.has_value());
        EXPECT_EQ(result.error(), ErrorCode::INVALID_PARAMS);
    }

    // Test case 4: Mixed buffer with one invalid (zero size) - should fail
    // validation
    {
        std::vector<RemoteBufferDesc> zero_size_buffer = {
            {"seg1", 0x1000, 10},
            {"seg2", 0x2000, 0},  // Invalid: zero size
            {"seg3", 0x3000, 25}};
        auto result = CallTransferDataToRemote(handle, zero_size_buffer);
        EXPECT_FALSE(result.has_value());
        EXPECT_EQ(result.error(), ErrorCode::INVALID_PARAMS);
    }

    // Test case 5: Valid buffers but TransferEngine not initialized
    // This simulates the actual transfer flow up to the point where
    // TransferEngine would perform RDMA operations
    {
        std::vector<RemoteBufferDesc> valid_buffers = {
            {"seg1", 0x1000, 20},
            {"seg2", 0x2000, 15}  // Total = 35 bytes, exact match
        };
        size_t total = 0;
        for (const auto& b : valid_buffers) total += b.size;
        EXPECT_EQ(total, test_data.size());

        // This will fail with INTERNAL_ERROR because TransferEngine is not
        // fully initialized (no metadata/RDMA connection in test environment).
        // In production with proper TransferEngine setup, this would succeed.
        auto result = CallTransferDataToRemote(handle, valid_buffers);
        EXPECT_FALSE(result.has_value());
        EXPECT_EQ(result.error(), ErrorCode::INTERNAL_ERROR);

        // NOTE: To fully test actual data transfer, you would need:
        // 1. TransferEngine initialized with RDMA fabric
        // 2. Remote segments registered and accessible
        // 3. Verify transferred data matches source data
        // Example production verification (not executable in unit test):
        //   char* remote_data = ...; // Access to remote buffer
        //   EXPECT_EQ(std::string(remote_data, test_data.size()), test_data);
    }
}

// Test TransferDataToRemote with actual data preparation
// This test validates the complete flow including data buffer handling
TEST_F(DataManagerTest, TransferDataToRemoteDataPreparation) {
    const std::string key = "transfer_prep_key";
    const std::string test_data =
        "DataTransferPreparationTest12345678901";  // 38 bytes

    // Store test data
    auto buffer = StringToBuffer(test_data);
    ASSERT_TRUE(data_manager_->Put(key, std::move(buffer), test_data.size())
                    .has_value());

    // Get handle to the stored data
    auto handle_result = data_manager_->Get(key);
    ASSERT_TRUE(handle_result.has_value());
    auto handle = handle_result.value();

    // Verify we can read the data from the handle
    ASSERT_TRUE(handle->loc.data.buffer);
    EXPECT_EQ(handle->loc.data.buffer->size(), test_data.size());
    char* data_ptr = reinterpret_cast<char*>(handle->loc.data.buffer->data());
    std::string retrieved_data(data_ptr, test_data.size());
    EXPECT_EQ(retrieved_data, test_data);

    // Prepare scatter-gather destination buffers
    // Simulate splitting data across multiple remote segments
    std::vector<RemoteBufferDesc> scatter_buffers = {
        {"segment_A", 0x1000, 15},  // First 15 bytes
        {"segment_B", 0x2000, 13},  // Next 13 bytes
        {"segment_C", 0x3000, 10}   // Last 10 bytes, total = 38
    };

    // Verify total size matches
    size_t total_size = 0;
    for (const auto& buf : scatter_buffers) {
        total_size += buf.size;
    }
    EXPECT_EQ(total_size, test_data.size());

    // Attempt transfer (will fail due to uninitialized TransferEngine in test
    // env)
    auto transfer_result = CallTransferDataToRemote(handle, scatter_buffers);

    // Expected to fail with INTERNAL_ERROR in test environment
    // In production with RDMA:
    // - Would succeed and return no error
    // - Data would be scattered across segment_A, segment_B, segment_C
    // - segment_A would contain "DataTransferPre" (15 bytes)
    // - segment_B would contain "parationTest1" (13 bytes)
    // - segment_C would contain "2345678901" (10 bytes)
    EXPECT_FALSE(transfer_result.has_value());
    EXPECT_EQ(transfer_result.error(), ErrorCode::INTERNAL_ERROR);
}

// Test TransferDataFromRemote validation
TEST_F(DataManagerTest, TransferDataFromRemoteValidation) {
    const std::string key = "transfer_from_key";
    const size_t data_size = 50;

    // Allocate space (simulate receiving data into this space)
    auto buffer = std::make_unique<char[]>(data_size);
    ASSERT_TRUE(
        data_manager_->Put(key, std::move(buffer), data_size).has_value());

    auto handle_result = data_manager_->Get(key);
    ASSERT_TRUE(handle_result.has_value());
    auto handle = handle_result.value();

    // Test invalid parameters
    {
        // Empty segment name
        std::vector<RemoteBufferDesc> invalid_buffers = {{"", 0x1000, 50}};
        auto result = CallTransferDataFromRemote(handle, invalid_buffers);
        EXPECT_FALSE(result.has_value());
        EXPECT_EQ(result.error(), ErrorCode::INVALID_PARAMS);
    }

    {
        // Zero size
        std::vector<RemoteBufferDesc> invalid_buffers = {{"seg1", 0x1000, 0}};
        auto result = CallTransferDataFromRemote(handle, invalid_buffers);
        EXPECT_FALSE(result.has_value());
        EXPECT_EQ(result.error(), ErrorCode::INVALID_PARAMS);
    }

    {
        // Valid parameters but TransferEngine not initialized
        std::vector<RemoteBufferDesc> valid_buffers = {{"seg1", 0x1000, 30},
                                                       {"seg2", 0x2000, 20}};
        auto result = CallTransferDataFromRemote(handle, valid_buffers);
        EXPECT_FALSE(result.has_value());
        EXPECT_EQ(result.error(), ErrorCode::INTERNAL_ERROR);
    }
}

// Test concurrent delete operations for thread safety
TEST_F(DataManagerTest, ConcurrentDeleteOperations) {
    const int num_keys = 20;
    std::vector<std::string> keys;

    // Create keys and put data
    for (int i = 0; i < num_keys; ++i) {
        std::string key = "concurrent_delete_key_" + std::to_string(i);
        keys.push_back(key);
        std::string data = "data_for_deletion_" + std::to_string(i);
        auto buffer = StringToBuffer(data);
        ASSERT_TRUE(data_manager_->Put(key, std::move(buffer), data.size())
                        .has_value());
    }

    // Verify all keys exist
    for (const auto& key : keys) {
        ASSERT_TRUE(data_manager_->Get(key).has_value());
    }

    // Delete all keys concurrently
    std::vector<std::thread> threads;
    std::atomic<int> delete_success_count{0};

    for (int i = 0; i < num_keys; ++i) {
        threads.emplace_back([this, &keys, &delete_success_count, i]() {
            if (data_manager_->Delete(keys[i])) {
                delete_success_count++;
            }
        });
    }

    for (auto& t : threads) {
        t.join();
    }

    EXPECT_EQ(delete_success_count, num_keys);

    // Verify all keys are deleted
    for (const auto& key : keys) {
        EXPECT_FALSE(data_manager_->Get(key).has_value());
    }
}

// Test repeated Put operations on the same key (overwrite behavior)
TEST_F(DataManagerTest, RepeatedPutSameKey) {
    const std::string key = "repeated_put_key";

    // First Put
    const std::string data1 = "FirstData";
    auto buffer1 = StringToBuffer(data1);
    ASSERT_TRUE(
        data_manager_->Put(key, std::move(buffer1), data1.size()).has_value());

    // Verify first data
    auto result1 = data_manager_->Get(key);
    ASSERT_TRUE(result1.has_value());
    char* ptr1 =
        reinterpret_cast<char*>(result1.value()->loc.data.buffer->data());
    EXPECT_EQ(std::string(ptr1, data1.size()), data1);

    // Second Put with different data (overwrite)
    const std::string data2 = "SecondDataLonger";
    auto buffer2 = StringToBuffer(data2);
    auto put_result2 =
        data_manager_->Put(key, std::move(buffer2), data2.size());

    // The behavior depends on implementation - it may fail or succeed
    // If it succeeds, verify the new data
    if (put_result2.has_value()) {
        auto result2 = data_manager_->Get(key);
        ASSERT_TRUE(result2.has_value());
        EXPECT_EQ(result2.value()->loc.data.buffer->size(), data2.size());
    }

    // Third Put with shorter data
    const std::string data3 = "Short";
    auto buffer3 = StringToBuffer(data3);
    // Delete first to ensure clean state
    data_manager_->Delete(key);
    ASSERT_TRUE(
        data_manager_->Put(key, std::move(buffer3), data3.size()).has_value());

    auto result3 = data_manager_->Get(key);
    ASSERT_TRUE(result3.has_value());
    char* ptr3 =
        reinterpret_cast<char*>(result3.value()->loc.data.buffer->data());
    EXPECT_EQ(std::string(ptr3, data3.size()), data3);
}

// Test boundary conditions with various data sizes
TEST_F(DataManagerTest, BoundaryConditionTests) {
    // Test 1: Single byte data
    {
        const std::string key = "single_byte_key";
        const std::string single_byte = "X";
        auto buffer = StringToBuffer(single_byte);
        ASSERT_TRUE(data_manager_->Put(key, std::move(buffer), 1).has_value());

        auto result = data_manager_->Get(key);
        ASSERT_TRUE(result.has_value());
        EXPECT_EQ(result.value()->loc.data.buffer->size(), 1);
    }

    // Test 2: Exact power-of-two sizes
    {
        const std::string key = "power_of_two_key";
        const size_t size = 64 * 1024;  // 64KB
        auto buffer = CreateTestData(size, "P2");
        ASSERT_TRUE(
            data_manager_->Put(key, std::move(buffer), size).has_value());

        auto result = data_manager_->Get(key);
        ASSERT_TRUE(result.has_value());
        EXPECT_EQ(result.value()->loc.data.buffer->size(), size);
    }

    // Test 3: Non-power-of-two sizes
    {
        const std::string key = "non_power_of_two_key";
        const size_t size = 100 * 1024 + 512;  // 100.5KB
        auto buffer = CreateTestData(size, "NP2");
        ASSERT_TRUE(
            data_manager_->Put(key, std::move(buffer), size).has_value());

        auto result = data_manager_->Get(key);
        ASSERT_TRUE(result.has_value());
        EXPECT_EQ(result.value()->loc.data.buffer->size(), size);
    }
}

// Test lock contention with 1025 concurrent Put operations
// Since there are only 1024 lock shards, at least 2 keys will map to the same
// lock
TEST_F(DataManagerTest, LockContentionTest) {
    const int num_keys = 1025;
    // Use the same initialization logic as DataManager
    const size_t kLockShardCount =
        GetEnvOr<size_t>("MOONCAKE_DM_LOCK_SHARD_COUNT", 1024);

    std::vector<std::string> keys;
    std::unordered_map<size_t, int> lock_usage_count;

    // Generate 1025 unique keys and calculate their lock indices
    for (int i = 0; i < num_keys; ++i) {
        std::string key = "contention_key_" + std::to_string(i);
        keys.push_back(key);

        // Calculate which lock shard this key maps to (same logic as
        // DataManager)
        size_t hash = std::hash<std::string>{}(key);
        size_t lock_index = hash % kLockShardCount;
        lock_usage_count[lock_index]++;
    }

    // Find locks with contention (multiple keys mapping to same lock)
    int contended_locks_num = 0;
    int used_locks_num = 0;
    for (const auto& [lock_idx, count] : lock_usage_count) {
        if (count > 1) {
            contended_locks_num++;
        }
        used_locks_num++;
    }

    // Log contention statistics
    LOG(INFO) << "=== Lock Contention Statistics ===";
    LOG(INFO) << "Total keys: " << num_keys;
    LOG(INFO) << "Total lock shards: " << kLockShardCount;
    LOG(INFO) << "Locks with contention (multiple keys): "
              << contended_locks_num;
    LOG(INFO) << "Contention ratio: "
              << (100.0 * (num_keys - used_locks_num) / num_keys) << "%";

    // Perform concurrent Put operations
    std::vector<tl::expected<void, ErrorCode>> results(num_keys);
    std::vector<std::thread> threads;
    std::mutex log_mutex;  // For thread-safe logging

    LOG(INFO) << "Starting " << num_keys << " concurrent Put operations...";
    auto start_time = std::chrono::steady_clock::now();

    for (int i = 0; i < num_keys; ++i) {
        threads.emplace_back([this, &keys, &results, i, &lock_usage_count,
                              kLockShardCount, &log_mutex]() {
            std::string data = "data_" + std::to_string(i);
            auto buffer = StringToBuffer(data);

            // Calculate lock index for this key
            size_t hash = std::hash<std::string>{}(keys[i]);
            size_t lock_index = hash % kLockShardCount;

            // Log if this key is in a contended lock
            bool is_contended = lock_usage_count[lock_index] > 1;

            results[i] =
                data_manager_->Put(keys[i], std::move(buffer), data.size());

            if (!results[i].has_value() && is_contended) {
                std::lock_guard<std::mutex> lock(log_mutex);
                LOG(ERROR) << "[CONTENTION FAILURE] Key: " << keys[i]
                           << " failed with error: "
                           << toString(results[i].error());
            }
        });
    }

    // Wait for all threads
    for (auto& t : threads) {
        t.join();
    }

    auto end_time = std::chrono::steady_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(
                        end_time - start_time)
                        .count();

    LOG(INFO) << "All " << num_keys << " Put operations completed in "
              << duration << " ms";

    // Verify all operations succeeded
    int success_count = 0;
    int failure_count = 0;
    for (int i = 0; i < num_keys; ++i) {
        if (results[i].has_value()) {
            success_count++;
        } else {
            failure_count++;
            LOG(ERROR) << "Put failed for key: " << keys[i]
                       << ", error: " << toString(results[i].error());
        }
    }

    LOG(INFO) << "=== Operation Results ===";
    LOG(INFO) << "Success: " << success_count << "/" << num_keys;
    LOG(INFO) << "Failure: " << failure_count << "/" << num_keys;
    LOG(INFO) << "Success rate: " << (100.0 * success_count / num_keys) << "%";

    // All operations should succeed even with lock contention
    EXPECT_EQ(success_count, num_keys)
        << "All Put operations should succeed even with lock contention";
    EXPECT_EQ(failure_count, 0)
        << "No operations should fail due to lock contention";

    // Verify all keys can be retrieved
    LOG(INFO) << "Verifying all keys can be retrieved...";
    int retrieved_count = 0;
    for (int i = 0; i < num_keys; ++i) {
        auto get_result = data_manager_->Get(keys[i]);
        if (get_result.has_value()) {
            retrieved_count++;
        } else {
            LOG(ERROR) << "Get failed for key: " << keys[i]
                       << ", error: " << toString(get_result.error());
        }
    }

    LOG(INFO) << "Retrieved: " << retrieved_count << "/" << num_keys;
    EXPECT_EQ(retrieved_count, num_keys)
        << "All keys should be retrievable after Put";
}

// Test concurrent Get and Delete operations to verify that removing read locks
// from DataManager::Get is safe. The TieredBackend's internal locking and
// shared_ptr reference counting should ensure thread safety.
TEST_F(DataManagerTest, ConcurrentGetAndDelete) {
    const int num_keys = 50;
    std::vector<std::string> keys;

    // Setup: Create keys and put data
    for (int i = 0; i < num_keys; ++i) {
        std::string key = "concurrent_get_delete_key_" + std::to_string(i);
        keys.push_back(key);
        std::string data = "test_data_" + std::to_string(i);
        auto buffer = StringToBuffer(data);
        ASSERT_TRUE(data_manager_->Put(key, std::move(buffer), data.size())
                        .has_value());
    }

    std::atomic<int> successful_gets{0};
    std::atomic<int> successful_deletes{0};
    std::atomic<int> expected_not_found{0};
    std::vector<std::thread> threads;

    // Launch concurrent Get and Delete operations on the same keys
    for (int i = 0; i < num_keys; ++i) {
        // Get thread
        threads.emplace_back(
            [this, &keys, &successful_gets, &expected_not_found, i]() {
                auto result = data_manager_->Get(keys[i]);
                if (result.has_value()) {
                    successful_gets++;
                    // Verify the handle is valid and data is accessible
                    EXPECT_NE(result.value()->loc.data.buffer, nullptr);
                } else {
                    // Key may have been deleted by the delete thread
                    expected_not_found++;
                }
            });

        // Delete thread
        threads.emplace_back([this, &keys, &successful_deletes, i]() {
            if (data_manager_->Delete(keys[i]).has_value()) {
                successful_deletes++;
            }
        });
    }

    for (auto& t : threads) {
        t.join();
    }

    LOG(INFO) << "=== Concurrent Get/Delete Results ===";
    LOG(INFO) << "Successful Gets: " << successful_gets;
    LOG(INFO) << "Successful Deletes: " << successful_deletes;
    LOG(INFO) << "Expected Not Found: " << expected_not_found;

    // All deletes should succeed (each key deleted exactly once)
    EXPECT_EQ(successful_deletes.load(), num_keys);
    // Gets + NotFound should equal num_keys (each key accessed exactly once)
    EXPECT_EQ(successful_gets.load() + expected_not_found.load(), num_keys);
}

// Test that AllocationHandle (shared_ptr) keeps data alive even after deletion
// from DataManager. This verifies the reference counting mechanism works
// correctly without the read lock in DataManager::Get.
TEST_F(DataManagerTest, HandleKeepsDataAliveAfterDelete) {
    const std::string key = "handle_lifetime_test_key";
    const std::string test_data = "HandleLifetimeTestData_1234567890";

    // Put data
    auto buffer = StringToBuffer(test_data);
    ASSERT_TRUE(data_manager_->Put(key, std::move(buffer), test_data.size())
                    .has_value());

    // Get handle (increases ref count)
    auto handle_result = data_manager_->Get(key);
    ASSERT_TRUE(handle_result.has_value());
    auto handle = handle_result.value();

    // Verify handle is valid
    ASSERT_NE(handle, nullptr);
    ASSERT_NE(handle->loc.data.buffer, nullptr);
    EXPECT_EQ(handle->loc.data.buffer->size(), test_data.size());

    // Delete the key from DataManager
    ASSERT_TRUE(data_manager_->Delete(key).has_value());

    // Verify key is no longer accessible via DataManager
    auto get_after_delete = data_manager_->Get(key);
    EXPECT_FALSE(get_after_delete.has_value());
    EXPECT_EQ(get_after_delete.error(), ErrorCode::INVALID_KEY);

    // But the handle we obtained earlier should still be valid!
    // This is because shared_ptr reference counting keeps the data alive
    ASSERT_NE(handle->loc.data.buffer, nullptr)
        << "Handle should still be valid after key deletion";
    EXPECT_EQ(handle->loc.data.buffer->size(), test_data.size())
        << "Data size should be unchanged";

    // Verify data content is still intact
    char* data_ptr = reinterpret_cast<char*>(handle->loc.data.buffer->data());
    std::string retrieved_data(data_ptr, test_data.size());
    EXPECT_EQ(retrieved_data, test_data)
        << "Data content should be unchanged after key deletion";

    LOG(INFO) << "Handle successfully kept data alive after deletion";
}

// Test local loopback transfer using segment_name="local"
// This tests the DataManager's ability to transfer data locally without RDMA
TEST_F(DataManagerTest, LocalLoopbackTransfer) {
    const size_t test_size = 1024 * 1024;  // 1MB test data

    // Create test data with recognizable pattern
    auto test_data = std::make_unique<char[]>(test_size);
    const std::string pattern = "LOCAL_LOOPBACK_TEST_";
    for (size_t i = 0; i < test_size; i++) {
        test_data[i] = pattern[i % pattern.size()];
    }

    // Store data in DataManager
    const std::string key = "local_loopback_test_key";
    auto put_result = data_manager_->Put(key, std::move(test_data), test_size);
    ASSERT_TRUE(put_result.has_value()) << "Failed to put data into DataManager";

    // Get handle to the stored data
    auto get_result = data_manager_->Get(key);
    ASSERT_TRUE(get_result.has_value()) << "Failed to get handle from DataManager";
    auto handle = get_result.value();

    // Allocate destination buffer
    std::vector<char> dest_buffer(test_size, 0);

    // Create RemoteBufferDesc with segment_name="local" for loopback transfer
    std::vector<RemoteBufferDesc> dest_buffers = {
        {"local", reinterpret_cast<uint64_t>(dest_buffer.data()), test_size}
    };

    // Perform local loopback transfer using ReadRemoteData
    auto read_result = data_manager_->ReadRemoteData(key, dest_buffers);
    ASSERT_TRUE(read_result.has_value())
        << "Local loopback transfer failed with error: "
        << toString(read_result.error());

    // Verify transferred data matches original
    const char* src_ptr = reinterpret_cast<const char*>(handle->loc.data.buffer->data());
    bool data_matches = (std::memcmp(src_ptr, dest_buffer.data(), test_size) == 0);
    EXPECT_TRUE(data_matches) << "Data mismatch after local loopback transfer";

    // Verify pattern in destination
    bool pattern_correct = true;
    for (size_t i = 0; i < 100; i++) {  // Check first 100 bytes
        if (dest_buffer[i] != pattern[i % pattern.size()]) {
            pattern_correct = false;
            break;
        }
    }
    EXPECT_TRUE(pattern_correct) << "Pattern verification failed";

    LOG(INFO) << "Local loopback transfer test PASSED! Transferred "
              << test_size << " bytes using segment_name='local'";
}

// Test local loopback WriteRemoteData using segment_name="local"
TEST_F(DataManagerTest, LocalLoopbackWriteRemoteData) {
    const size_t test_size = 512 * 1024;  // 512KB test data

    // Create source buffer with test data
    std::vector<char> src_buffer(test_size);
    const std::string pattern = "WRITE_LOOPBACK_DATA_";
    for (size_t i = 0; i < test_size; i++) {
        src_buffer[i] = pattern[i % pattern.size()];
    }

    // Create RemoteBufferDesc with segment_name="local"
    std::vector<RemoteBufferDesc> src_buffers = {
        {"local", reinterpret_cast<uint64_t>(src_buffer.data()), test_size}
    };

    // Write data using local loopback
    const std::string key = "local_write_test_key";
    auto write_result = data_manager_->WriteRemoteData(key, src_buffers);
    ASSERT_TRUE(write_result.has_value())
        << "Local loopback WriteRemoteData failed with error: "
        << toString(write_result.error());

    // Verify data was stored correctly by reading it back
    auto get_result = data_manager_->Get(key);
    ASSERT_TRUE(get_result.has_value()) << "Failed to get written data";
    auto handle = get_result.value();

    // Compare stored data with original
    const char* stored_ptr = reinterpret_cast<const char*>(handle->loc.data.buffer->data());
    bool data_matches = (std::memcmp(stored_ptr, src_buffer.data(), test_size) == 0);
    EXPECT_TRUE(data_matches) << "Stored data does not match source after WriteRemoteData";

    LOG(INFO) << "Local loopback WriteRemoteData test PASSED! Wrote "
              << test_size << " bytes using segment_name='local'";
}

}  // namespace mooncake
