# OpLog 主备同步方案 - 宣传文案

## 背景动机

Mooncake Store 当前高可用模式虽然实现了 Leader 选举，但 Standby Master 在等待期间不执行任何数据同步操作，导致 Primary 故障后 Standby 提升时 metadata 不完整，需要长时间重建，严重影响服务可用性。

## 设计亮点

**核心创新**：基于 etcd 的 OpLog 主备同步机制

1. **可靠的数据同步**：利用 etcd 的强一致性和 Watch 机制，实现 Primary 到 Standby 的实时数据同步，保证 Standby 与 Primary 数据完全一致

2. **快速故障恢复**：Standby 持续同步 OpLog，提升为 Primary 时 metadata 完整，无需重建，故障恢复时间从分钟级降低到秒级

3. **高效设计**：只记录关键操作（PUT/DELETE），不记录高频的租约续约，OpLog 大小减少 90%+；通过全局和 key 级别双重序列号保证顺序

4. **智能容错**：检测到乱序时自动回滚重放，定期清理过期内存，与现有快照机制无缝集成

**技术价值**：将高可用模式从不稳定状态提升到生产可用，为 LLM 推理场景提供可靠的高可用保障。

---

## 群内宣传文案（优化版）

MoonCake 社区提供了高效的 KV cache 存储方案，极大提高了推理性能，但其高可用性较弱，导致在大规模生产级应用上使用受限。

基于此背景，我在社区提出了一种基于热备的高可用架构，已被社区接受。RFC 链接：https://github.com/kvcache-ai/Mooncake/issues/1200

**设计亮点**：

1. **基于 etcd 的 OpLog 机制**：利用强一致性和 Watch 实现实时同步，保证 Standby 与 Primary 数据完全一致

2. **秒级故障恢复**：Standby 持续同步，故障恢复从分钟级降至秒级

3. **高效设计**：只记录关键操作，OpLog 大小减少 90%+，双重序列号保证顺序

4. **智能容错**：乱序自动回滚重放，定期内存清理，与快照机制无缝集成

**技术价值**：将高可用模式从基本不可用提升到生产可用，为 LLM 推理提供可靠保障。

欢迎大家 review 该 RFC，多提意见哈~
